Number of trainable / all parameters: 25874440 / 25874440

Sg2ScDiffusion(
  (network): Sg2ScTransformerDiffusionWrapper(
    (node_embed): Sequential(
      (0): Embedding(25, 512)
      (1): GELU(approximate='none')
      (2): Linear(in_features=512, out_features=512, bias=True)
    )
    (node_proj_in): Linear(in_features=1800, out_features=512, bias=True)
    (edge_embed): Sequential(
      (0): Embedding(11, 128)
      (1): GELU(approximate='none')
      (2): Linear(in_features=128, out_features=128, bias=True)
    )
    (time_embed): Sequential(
      (0): Timestep()
      (1): TimestepEmbed(
        (mlp): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=128, out_features=128, bias=True)
        )
      )
    )
    (transformer_blocks): ModuleList(
      (0-4): 5 x GraphTransformerBlock(
        (graph_attn): GraphAttention(
          (to_q): Linear(in_features=512, out_features=512, bias=False)
          (to_k): Linear(in_features=512, out_features=512, bias=False)
          (to_v): Linear(in_features=512, out_features=512, bias=False)
          (to_out): Sequential(
            (0): Linear(in_features=512, out_features=512, bias=True)
            (1): Dropout(p=0.1, inplace=False)
          )
          (to_e_mul): Linear(in_features=128, out_features=512, bias=False)
          (to_e_add): Linear(in_features=128, out_features=512, bias=False)
          (to_e_out): Sequential(
            (0): Linear(in_features=512, out_features=128, bias=True)
            (1): Dropout(p=0.1, inplace=False)
          )
        )
        (ff_x): FeedForward(
          (mlp): Sequential(
            (0): GEGLU(
              (proj): Linear(in_features=512, out_features=4096, bias=True)
            )
            (1): Dropout(p=0.1, inplace=False)
            (2): Linear(in_features=2048, out_features=512, bias=True)
          )
        )
        (ff_e): FeedForward(
          (mlp): Sequential(
            (0): GEGLU(
              (proj): Linear(in_features=128, out_features=1024, bias=True)
            )
            (1): Dropout(p=0.1, inplace=False)
            (2): Linear(in_features=512, out_features=128, bias=True)
          )
        )
        (ga_x_norm): AdaLayerNorm(
          (gelu): GELU(approximate='none')
          (linear): Linear(in_features=128, out_features=1024, bias=True)
          (layernorm): LayerNorm((512,), eps=1e-05, elementwise_affine=False)
        )
        (ff_x_norm): AdaLayerNorm(
          (gelu): GELU(approximate='none')
          (linear): Linear(in_features=128, out_features=1024, bias=True)
          (layernorm): LayerNorm((512,), eps=1e-05, elementwise_affine=False)
        )
        (ga_e_norm): AdaLayerNorm(
          (gelu): GELU(approximate='none')
          (linear): Linear(in_features=128, out_features=256, bias=True)
          (layernorm): LayerNorm((128,), eps=1e-05, elementwise_affine=False)
        )
        (ff_e_norm): AdaLayerNorm(
          (gelu): GELU(approximate='none')
          (linear): Linear(in_features=128, out_features=256, bias=True)
          (layernorm): LayerNorm((128,), eps=1e-05, elementwise_affine=False)
        )
      )
    )
    (proj_out): Sequential(
      (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (1): Linear(in_features=512, out_features=8, bias=True)
    )
  )
)